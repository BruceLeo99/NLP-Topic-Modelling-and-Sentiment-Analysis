{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYynTCm3XYM3"
   },
   "source": [
    "# Lab6.4-Topic-classification-BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6A5GywwXTs5"
   },
   "source": [
    "Copyright: Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Nj3ZMRwg3kv"
   },
   "source": [
    "In this notebook, we demonstrate how to fine-tune BERT for topic classification.\n",
    "\n",
    "We will use the [simpletransformers library](https://simpletransformers.ai/):\n",
    " wrapper for the [huggingface transformers library](https://huggingface.co/) on PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3anR6UiXhGVs"
   },
   "source": [
    "We are going to run the notebook on [colab](https://colab.research.google.com/?utm_source=scs-index), which has (limited) free access to GPUs.\n",
    "\n",
    "You need to enable GPUs for the notebook:\n",
    "\n",
    "* navigate to Edit → Notebook Settings\n",
    "* select GPU from the Hardware Accelerator drop-down\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xqo_5kOniUzs"
   },
   "source": [
    "### Install/import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqfPejIjiG6z"
   },
   "source": [
    "Install the simpletransformers library (restart your runtime after the installation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ps0tGvA8qiSP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: simpletransformers in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (0.70.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from simpletransformers) (1.26.2)\n",
      "Requirement already satisfied: requests in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from simpletransformers) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.47.0 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from simpletransformers) (4.66.1)\n",
      "Requirement already satisfied: regex in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from simpletransformers) (2023.10.3)\n",
      "Requirement already satisfied: transformers>=4.31.0 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from simpletransformers) (4.39.3)\n",
      "Requirement already satisfied: datasets in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from simpletransformers) (2.18.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from simpletransformers) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from simpletransformers) (1.3.2)\n",
      "Requirement already satisfied: seqeval in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from simpletransformers) (1.2.2)\n",
      "Requirement already satisfied: tensorboard in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from simpletransformers) (2.15.1)\n",
      "Requirement already satisfied: tensorboardx in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from simpletransformers) (2.6.2.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from simpletransformers) (2.1.4)\n",
      "Requirement already satisfied: tokenizers in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from simpletransformers) (0.15.2)\n",
      "Requirement already satisfied: wandb>=0.10.32 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from simpletransformers) (0.16.6)\n",
      "Requirement already satisfied: streamlit in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from simpletransformers) (1.33.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from simpletransformers) (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.47.0->simpletransformers) (0.4.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from transformers>=4.31.0->simpletransformers) (3.13.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from transformers>=4.31.0->simpletransformers) (0.22.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from transformers>=4.31.0->simpletransformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from transformers>=4.31.0->simpletransformers) (6.0.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from transformers>=4.31.0->simpletransformers) (0.4.2)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from wandb>=0.10.32->simpletransformers) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from wandb>=0.10.32->simpletransformers) (3.1.43)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from wandb>=0.10.32->simpletransformers) (5.9.6)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from wandb>=0.10.32->simpletransformers) (1.45.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from wandb>=0.10.32->simpletransformers) (0.4.0)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from wandb>=0.10.32->simpletransformers) (1.3.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from wandb>=0.10.32->simpletransformers) (69.0.2)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from wandb>=0.10.32->simpletransformers) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from wandb>=0.10.32->simpletransformers) (4.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from requests->simpletransformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from requests->simpletransformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from requests->simpletransformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from requests->simpletransformers) (2023.11.17)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from datasets->simpletransformers) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from datasets->simpletransformers) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from datasets->simpletransformers) (0.3.8)\n",
      "Requirement already satisfied: xxhash in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from datasets->simpletransformers) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from datasets->simpletransformers) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets->simpletransformers) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from datasets->simpletransformers) (3.9.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from pandas->simpletransformers) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from pandas->simpletransformers) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from pandas->simpletransformers) (2023.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn->simpletransformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn->simpletransformers) (3.2.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from streamlit->simpletransformers) (5.3.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from streamlit->simpletransformers) (1.7.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from streamlit->simpletransformers) (5.3.2)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from streamlit->simpletransformers) (10.1.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from streamlit->simpletransformers) (13.7.1)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from streamlit->simpletransformers) (8.2.3)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from streamlit->simpletransformers) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from streamlit->simpletransformers) (4.8.0)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from streamlit->simpletransformers) (0.8.1b0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from streamlit->simpletransformers) (6.3.3)\n",
      "Requirement already satisfied: watchdog>=2.1.5 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from streamlit->simpletransformers) (4.0.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard->simpletransformers) (2.0.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard->simpletransformers) (1.59.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard->simpletransformers) (2.24.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard->simpletransformers) (1.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard->simpletransformers) (3.5.1)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard->simpletransformers) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard->simpletransformers) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard->simpletransformers) (3.0.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (4.20.0)\n",
      "Requirement already satisfied: toolz in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (0.12.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->datasets->simpletransformers) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->datasets->simpletransformers) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->datasets->simpletransformers) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->datasets->simpletransformers) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->datasets->simpletransformers) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from aiohttp->datasets->simpletransformers) (4.0.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from GitPython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (4.0.11)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->simpletransformers) (1.3.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from rich<14,>=10.14.0->streamlit->simpletransformers) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from rich<14,>=10.14.0->streamlit->simpletransformers) (2.17.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from werkzeug>=1.0.1->tensorboard->simpletransformers) (2.1.3)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (5.0.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (2023.11.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (0.31.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (0.13.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit->simpletransformers) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->simpletransformers) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\yixin\\appdata\\roaming\\python\\python310\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->simpletransformers) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install simpletransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "CQ6PxcAqRV_C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\yixin\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7xjzXFewjHrL"
   },
   "source": [
    "Import [the 20 newsgroups text dataset](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html).\n",
    "\n",
    "The dataset contains around 18,000 newsgroups posts on 20 topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "x8fP7uGBSIno"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# load only a sub-selection of the categories (4 in our case)\n",
    "categories = ['alt.atheism', 'comp.graphics', 'sci.med', 'sci.space']\n",
    "\n",
    "# remove the headers, footers and quotes (to avoid overfitting)\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), categories=categories, random_state=42)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), categories=categories, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xRCPZ9B3j_Al"
   },
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0SfvjOA8n--Q"
   },
   "source": [
    "The target attribute is the integer index of the category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qJGlxNCHSO4A"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 594, 3: 593, 1: 584, 0: 480})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2nSwVV77WTNo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 396, 3: 394, 1: 389, 0: 319})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(newsgroups_test.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DsjZUZJQkJLb"
   },
   "source": [
    "Convert data to pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "FZycCZ1nTf8B"
   },
   "outputs": [],
   "source": [
    "train = pd.DataFrame({'text': newsgroups_train.data, 'labels': newsgroups_train.target})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Cv_W-vjoVi9T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2251\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WHile we are on the subject of the shuttle sof...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There is a program called Graphic Workshop you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My girlfriend is in pain from kidney stones. S...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I think that's the correct spelling..\\n\\tI am ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels\n",
       "0  WHile we are on the subject of the shuttle sof...       3\n",
       "1  There is a program called Graphic Workshop you...       1\n",
       "2                                                          2\n",
       "3  My girlfriend is in pain from kidney stones. S...       2\n",
       "4  I think that's the correct spelling..\\n\\tI am ...       2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train))\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "15HS5hYJWE72"
   },
   "outputs": [],
   "source": [
    "test = pd.DataFrame({'text': newsgroups_test.data, 'labels': newsgroups_test.target})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "pclWtf61WFFi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1498\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nAnd guess who's here in your place.\\n\\nPleas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Does anyone know if any of Currier and Ives et...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>=FLAME ON\\n=\\n=Reading through the posts about...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nBut in this case I said I hoped that BCCI wa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nIn the kind I have made I used a Lite sour c...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels\n",
       "0  \\nAnd guess who's here in your place.\\n\\nPleas...       1\n",
       "1  Does anyone know if any of Currier and Ives et...       1\n",
       "2  =FLAME ON\\n=\\n=Reading through the posts about...       2\n",
       "3  \\nBut in this case I said I hoped that BCCI wa...       0\n",
       "4  \\nIn the kind I have made I used a Lite sour c...       2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(test))\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUyLCGQ-kewk"
   },
   "source": [
    "Use a subset (10%) of the training set as a development set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "HjziUjfO6rfd"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, dev = train_test_split(train, test_size=0.1, random_state=0,\n",
    "                               stratify=train[['labels']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "TW0f7IXg6zh-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025\n",
      "train: labels\n",
      "0         432\n",
      "1         525\n",
      "2         534\n",
      "3         534\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>I wonder how many atheists out there care to s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>We are interested in purchasing a grayscale pr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>Dear Binary Newsers,\\n\\nI am looking for Quick...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  labels\n",
       "559   I wonder how many atheists out there care to s...       0\n",
       "2060  We are interested in purchasing a grayscale pr...       1\n",
       "1206  Dear Binary Newsers,\\n\\nI am looking for Quick...       1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(\"train:\", train[['labels']].value_counts(sort=False))\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "R6WPhHVV67FB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226\n",
      "dev: labels\n",
      "0         48\n",
      "1         59\n",
      "2         60\n",
      "3         59\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>I'd dump him.  Rude is rude and it seems he en...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761</th>\n",
       "      <td>Hi Everyone ::\\n\\nI am  looking for  some soft...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>A friend of mine has been diagnosed with Psori...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  labels\n",
       "1570  I'd dump him.  Rude is rude and it seems he en...       2\n",
       "1761  Hi Everyone ::\\n\\nI am  looking for  some soft...       1\n",
       "455   A friend of mine has been diagnosed with Psori...       2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(dev))\n",
    "print(\"dev:\", dev[['labels']].value_counts(sort=False))\n",
    "dev.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9xr9lbqkqin"
   },
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRNPxM1GkxDM"
   },
   "source": [
    "Define model's configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "8wXwk5muuVNd"
   },
   "outputs": [],
   "source": [
    "# Model configuration # https://simpletransformers.ai/docs/usage/#configuring-a-simple-transformers-model\n",
    "model_args = ClassificationArgs()\n",
    "\n",
    "model_args.overwrite_output_dir=True # overwrite existing saved models in the same directory\n",
    "model_args.evaluate_during_training=True # to perform evaluation while training the model\n",
    "# (eval data should be passed to the training method)\n",
    "\n",
    "model_args.num_train_epochs=10 # number of epochs\n",
    "model_args.train_batch_size=32 # batch size\n",
    "model_args.learning_rate=4e-6 # learning rate\n",
    "model_args.max_seq_length=256 # maximum sequence length\n",
    "# Note! Increasing max_seq_len may provide better performance, but training time will increase.\n",
    "# For educational purposes, we set max_seq_len to 256.\n",
    "\n",
    "# Early stopping to combat overfitting: https://simpletransformers.ai/docs/tips-and-tricks/#using-early-stopping\n",
    "model_args.use_early_stopping=True\n",
    "model_args.early_stopping_delta=0.01 # \"The improvement over best_eval_loss necessary to count as a better checkpoint\"\n",
    "model_args.early_stopping_metric='eval_loss'\n",
    "model_args.early_stopping_metric_minimize=True\n",
    "model_args.early_stopping_patience=2\n",
    "model_args.evaluate_during_training_steps=32 # how often you want to run validation in terms of training steps (or batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTPzxUZS0X-Z"
   },
   "source": [
    "With this configuration, the training will terminate if the eval_loss on the evaluation data does not improve upon the best eval_loss by at least 0.01 for 2 consecutive evaluations.\n",
    "\n",
    "An evaluation will occur once for every 32 training steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "fexZQazDm0pu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each epoch will have 64 steps.\n"
     ]
    }
   ],
   "source": [
    "# Checking steps per epoch\n",
    "steps_per_epoch = int(np.ceil(len(train) / float(model_args.train_batch_size)))\n",
    "print('Each epoch will have {:,} steps.'.format(steps_per_epoch)) # 64 steps = validating 2 times per epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M3wUHcjXyg5C"
   },
   "source": [
    "Load the pre-trained model: model_type = bert; model_name = [bert-base-cased](https://huggingface.co/bert-base-cased) (specifies the exact architecture and trained weights to use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "g97m6L_ZqhkK"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a557f277e64825a9cbca9f7222db28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yixin\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\yixin\\.cache\\huggingface\\hub\\models--bert-base-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41617cbe895c41cdb1e3f679454f4bbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85dcdeb1d201456db2e017ea3ca02a39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf59b0b4f61b4a8f96f46cf3b5c877c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a53f51160284f5ab6f20b1c830d2ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = ClassificationModel('bert', 'bert-base-cased', num_labels=4, args=model_args, use_cuda=False) # CUDA is enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "O9P0dxJeeN91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassificationArgs(adafactor_beta1=None\n",
      " adafactor_clip_threshold=1.0\n",
      " adafactor_decay_rate=-0.8\n",
      " adafactor_eps=(1e-30\n",
      " 0.001)\n",
      " adafactor_relative_step=True\n",
      " adafactor_scale_parameter=True\n",
      " adafactor_warmup_init=True\n",
      " adam_betas=(0.9\n",
      " 0.999)\n",
      " adam_epsilon=1e-08\n",
      " best_model_dir='outputs/best_model'\n",
      " cache_dir='cache_dir/'\n",
      " config={}\n",
      " cosine_schedule_num_cycles=0.5\n",
      " custom_layer_parameters=[]\n",
      " custom_parameter_groups=[]\n",
      " dataloader_num_workers=0\n",
      " do_lower_case=False\n",
      " dynamic_quantize=False\n",
      " early_stopping_consider_epochs=False\n",
      " early_stopping_delta=0.01\n",
      " early_stopping_metric='eval_loss'\n",
      " early_stopping_metric_minimize=True\n",
      " early_stopping_patience=2\n",
      " encoding=None\n",
      " eval_batch_size=100\n",
      " evaluate_during_training=True\n",
      " evaluate_during_training_silent=True\n",
      " evaluate_during_training_steps=32\n",
      " evaluate_during_training_verbose=False\n",
      " evaluate_each_epoch=True\n",
      " fp16=False\n",
      " gradient_accumulation_steps=1\n",
      " learning_rate=4e-06\n",
      " local_rank=-1\n",
      " logging_steps=50\n",
      " loss_type=None\n",
      " loss_args={}\n",
      " manual_seed=None\n",
      " max_grad_norm=1.0\n",
      " max_seq_length=256\n",
      " model_name='bert-base-cased'\n",
      " model_type='bert'\n",
      " multiprocessing_chunksize=-1\n",
      " n_gpu=1\n",
      " no_cache=False\n",
      " no_save=False\n",
      " not_saved_args=[]\n",
      " num_train_epochs=10\n",
      " optimizer='AdamW'\n",
      " output_dir='outputs/'\n",
      " overwrite_output_dir=True\n",
      " polynomial_decay_schedule_lr_end=1e-07\n",
      " polynomial_decay_schedule_power=1.0\n",
      " process_count=14\n",
      " quantized_model=False\n",
      " reprocess_input_data=True\n",
      " save_best_model=True\n",
      " save_eval_checkpoints=True\n",
      " save_model_every_epoch=True\n",
      " save_optimizer_and_scheduler=True\n",
      " save_steps=2000\n",
      " scheduler='linear_schedule_with_warmup'\n",
      " silent=False\n",
      " skip_special_tokens=True\n",
      " tensorboard_dir=None\n",
      " thread_count=None\n",
      " tokenizer_name='bert-base-cased'\n",
      " tokenizer_type=None\n",
      " train_batch_size=32\n",
      " train_custom_parameters_only=False\n",
      " trust_remote_code=False\n",
      " use_cached_eval_features=False\n",
      " use_early_stopping=True\n",
      " use_hf_datasets=False\n",
      " use_multiprocessing=True\n",
      " use_multiprocessing_for_evaluation=True\n",
      " wandb_kwargs={}\n",
      " wandb_project=None\n",
      " warmup_ratio=0.06\n",
      " warmup_steps=0\n",
      " weight_decay=0.0\n",
      " model_class='ClassificationModel'\n",
      " labels_list=[0\n",
      " 1\n",
      " 2\n",
      " 3]\n",
      " labels_map={}\n",
      " lazy_delimiter='\\t'\n",
      " lazy_labels_column=1\n",
      " lazy_loading=False\n",
      " lazy_loading_start_line=1\n",
      " lazy_text_a_column=None\n",
      " lazy_text_b_column=None\n",
      " lazy_text_column=0\n",
      " onnx=False\n",
      " regression=False\n",
      " sliding_window=False\n",
      " special_tokens_list=[]\n",
      " stride=0.8\n",
      " tie_value=1)\n"
     ]
    }
   ],
   "source": [
    "print(str(model.args).replace(',', '\\n')) # model args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKkGuau2lv7r"
   },
   "source": [
    "Fine-tuning the model (takes a while)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "NXHd3iwFuX_z"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ccdc916a9b438d901d3787868151d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a70b0b4103d84aac887927ea77d6613b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c4fdc8dd9a743f7a2a0041cf59ff526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 10:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c897791f8bf64e22a023d88477939b4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m _, history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdev\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\simpletransformers\\classification\\classification_model.py:630\u001b[0m, in \u001b[0;36mClassificationModel.train_model\u001b[1;34m(self, train_df, multi_label, output_dir, show_running_loss, args, eval_df, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    621\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[0;32m    622\u001b[0m     train_dataset,\n\u001b[0;32m    623\u001b[0m     sampler\u001b[38;5;241m=\u001b[39mtrain_sampler,\n\u001b[0;32m    624\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtrain_batch_size,\n\u001b[0;32m    625\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdataloader_num_workers,\n\u001b[0;32m    626\u001b[0m )\n\u001b[0;32m    628\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(output_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 630\u001b[0m global_step, training_details \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[0;32m    631\u001b[0m     train_dataloader,\n\u001b[0;32m    632\u001b[0m     output_dir,\n\u001b[0;32m    633\u001b[0m     multi_label\u001b[38;5;241m=\u001b[39mmulti_label,\n\u001b[0;32m    634\u001b[0m     show_running_loss\u001b[38;5;241m=\u001b[39mshow_running_loss,\n\u001b[0;32m    635\u001b[0m     eval_df\u001b[38;5;241m=\u001b[39meval_df,\n\u001b[0;32m    636\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    637\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    638\u001b[0m )\n\u001b[0;32m    640\u001b[0m \u001b[38;5;66;03m# model_to_save = self.model.module if hasattr(self.model, \"module\") else self.model\u001b[39;00m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;66;03m# model_to_save.save_pretrained(output_dir)\u001b[39;00m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;66;03m# self.tokenizer.save_pretrained(output_dir)\u001b[39;00m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;66;03m# torch.save(self.args, os.path.join(output_dir, \"training_args.bin\"))\u001b[39;00m\n\u001b[0;32m    644\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_model(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\simpletransformers\\classification\\classification_model.py:995\u001b[0m, in \u001b[0;36mClassificationModel.train\u001b[1;34m(self, train_dataloader, output_dir, multi_label, show_running_loss, eval_df, test_df, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    986\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_model(\n\u001b[0;32m    987\u001b[0m         output_dir_current, optimizer, scheduler, model\u001b[38;5;241m=\u001b[39mmodel\n\u001b[0;32m    988\u001b[0m     )\n\u001b[0;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mevaluate_during_training \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    991\u001b[0m     args\u001b[38;5;241m.\u001b[39mevaluate_during_training_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    992\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m global_step \u001b[38;5;241m%\u001b[39m args\u001b[38;5;241m.\u001b[39mevaluate_during_training_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    993\u001b[0m ):\n\u001b[0;32m    994\u001b[0m     \u001b[38;5;66;03m# Only evaluate when single GPU otherwise metrics may not average well\u001b[39;00m\n\u001b[1;32m--> 995\u001b[0m     results, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_model(\n\u001b[0;32m    996\u001b[0m         eval_df,\n\u001b[0;32m    997\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose \u001b[38;5;129;01mand\u001b[39;00m args\u001b[38;5;241m.\u001b[39mevaluate_during_training_verbose,\n\u001b[0;32m    998\u001b[0m         silent\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mevaluate_during_training_silent,\n\u001b[0;32m    999\u001b[0m         wandb_log\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1001\u001b[0m     )\n\u001b[0;32m   1003\u001b[0m     output_dir_current \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m   1004\u001b[0m         output_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoint-\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(global_step)\n\u001b[0;32m   1005\u001b[0m     )\n\u001b[0;32m   1007\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39msave_eval_checkpoints:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\simpletransformers\\classification\\classification_model.py:1359\u001b[0m, in \u001b[0;36mClassificationModel.eval_model\u001b[1;34m(self, eval_df, multi_label, output_dir, verbose, silent, wandb_log, **kwargs)\u001b[0m\n\u001b[0;32m   1355\u001b[0m     output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39moutput_dir\n\u001b[0;32m   1357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_move_model_to_device()\n\u001b[1;32m-> 1359\u001b[0m result, model_outputs, wrong_preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[0;32m   1360\u001b[0m     eval_df,\n\u001b[0;32m   1361\u001b[0m     output_dir,\n\u001b[0;32m   1362\u001b[0m     multi_label\u001b[38;5;241m=\u001b[39mmulti_label,\n\u001b[0;32m   1363\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   1364\u001b[0m     silent\u001b[38;5;241m=\u001b[39msilent,\n\u001b[0;32m   1365\u001b[0m     wandb_log\u001b[38;5;241m=\u001b[39mwandb_log,\n\u001b[0;32m   1366\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1367\u001b[0m )\n\u001b[0;32m   1368\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults\u001b[38;5;241m.\u001b[39mupdate(result)\n\u001b[0;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\simpletransformers\\classification\\classification_model.py:1599\u001b[0m, in \u001b[0;36mClassificationModel.evaluate\u001b[1;34m(self, eval_df, output_dir, multi_label, prefix, verbose, silent, wandb_log, **kwargs)\u001b[0m\n\u001b[0;32m   1596\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m multi_label:\n\u001b[0;32m   1597\u001b[0m         preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(preds, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m-> 1599\u001b[0m result, wrong \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(\n\u001b[0;32m   1600\u001b[0m     preds, model_outputs, out_label_ids, eval_examples, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1601\u001b[0m )\n\u001b[0;32m   1602\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m eval_loss\n\u001b[0;32m   1603\u001b[0m results\u001b[38;5;241m.\u001b[39mupdate(result)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\simpletransformers\\classification\\classification_model.py:1929\u001b[0m, in \u001b[0;36mClassificationModel.compute_metrics\u001b[1;34m(self, preds, model_outputs, labels, eval_examples, multi_label, **kwargs)\u001b[0m\n\u001b[0;32m   1927\u001b[0m mcc \u001b[38;5;241m=\u001b[39m matthews_corrcoef(labels, preds)\n\u001b[0;32m   1928\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(labels, preds)\n\u001b[1;32m-> 1929\u001b[0m f1 \u001b[38;5;241m=\u001b[39m \u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1930\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnum_labels \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1931\u001b[0m     tn, fp, fn, tp \u001b[38;5;241m=\u001b[39m confusion_matrix(labels, preds, labels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mravel()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1239\u001b[0m, in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m   1071\u001b[0m     {\n\u001b[0;32m   1072\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1097\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1098\u001b[0m ):\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \n\u001b[0;32m   1101\u001b[0m \u001b[38;5;124;03m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1237\u001b[0m \u001b[38;5;124;03m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[0;32m   1238\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfbeta_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1240\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1248\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\_param_validation.py:187\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    185\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    189\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1413\u001b[0m, in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1251\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m   1252\u001b[0m     {\n\u001b[0;32m   1253\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1280\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1281\u001b[0m ):\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m \n\u001b[0;32m   1284\u001b[0m \u001b[38;5;124;03m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1410\u001b[0m \u001b[38;5;124;03m    0.38...\u001b[39;00m\n\u001b[0;32m   1411\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1413\u001b[0m     _, _, f, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1414\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1415\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1419\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf-score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1421\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1423\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\_param_validation.py:187\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    185\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    189\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1724\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1566\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[0;32m   1567\u001b[0m \n\u001b[0;32m   1568\u001b[0m \u001b[38;5;124;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1721\u001b[0m \u001b[38;5;124;03m array([2, 2, 2]))\u001b[39;00m\n\u001b[0;32m   1722\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1723\u001b[0m zero_division_value \u001b[38;5;241m=\u001b[39m _check_zero_division(zero_division)\n\u001b[1;32m-> 1724\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1726\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1727\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1518\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1517\u001b[0m             average_options\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1518\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1519\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget is \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m but average=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1520\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoose another average setting, one of \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (y_type, average_options)\n\u001b[0;32m   1521\u001b[0m         )\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1523\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1524\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote that pos_label (set to \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) is ignored when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage != \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m). You may use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1528\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1529\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "_, history = model.train_model(train, eval_df=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hLqlJq-N70Fg"
   },
   "outputs": [],
   "source": [
    "# Training and evaluation loss\n",
    "_, history = model.train_model(train, eval_df=dev)\n",
    "train_loss = history['train_loss']\n",
    "eval_loss = history['eval_loss']\n",
    "plt.plot(train_loss, label='Training loss')\n",
    "plt.plot(eval_loss, label='Evaluation loss')\n",
    "plt.title('Training and evaluation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4KSWJoKb9q2x"
   },
   "source": [
    "* Loss measures the “goodness” of your model\n",
    "\n",
    "* The smaller the loss, the better the classifier is at modeling the relationship between the input data and the output targets\n",
    "\n",
    "* But you need to be careful not to overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kEARE6SR_wb8"
   },
   "source": [
    "In our case, we stopped training because eval_loss loss did not improve upon the best eval_loss by at least 0.01 for 2 consecutive evaluations.\n",
    "\n",
    "We can observe fluctuations in the training loss, but overall it is decreasing.\n",
    "We can have a smoother learning curve by varying hyperparameters, e.g., learning rate, batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FfhYbPEN72Qf"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "result, model_outputs, wrong_predictions = model.eval_model(dev)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6gtZCsKLImi"
   },
   "source": [
    "* mcc: [ Matthews correlation coefficient](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html)\n",
    "\n",
    "* eval_loss: Cross Entropy Loss for dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8M1m93Ol9cT"
   },
   "source": [
    "Make predictions with the model (predict the labels of the documents in the test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JHf8BtGxugLK"
   },
   "outputs": [],
   "source": [
    "predicted, probabilities = model.predict(test.text.to_list())\n",
    "test['predicted'] = predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trJHLdjCmGsB"
   },
   "source": [
    "Test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q7rbQGLSvtdp"
   },
   "outputs": [],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVfBUoE0mQ9v"
   },
   "source": [
    "Evaluate the model's performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JUsJ8gFDuoTh"
   },
   "outputs": [],
   "source": [
    "# Result (note: your result can be different due to randomness in operations)\n",
    "print(classification_report(test['labels'], test['predicted']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xh-_lL5Wl-0a"
   },
   "source": [
    "### End of this notebook."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
